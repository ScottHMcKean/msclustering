---
title: "read_output_csv"
author: "Scott McKean"
date: "18/07/2019"
output: html_document
---

```{r setup, include=FALSE}
library(data.table)
library(tidyverse)
library(purrr)
library(furrr)
```

# List Path
```{r}
csv_path <- '~/2_processed_ms_results/output_ms_only/'
```
# Get cluster files

```{r}
registerDoParallel(cores=60)
cluster_files <- list.files(csv_path, pattern = 'clusters', full.names = TRUE)
tagged_ms_files <- list.files(csv_path, pattern = 'gmm_result', full.names = TRUE)
cluster_dfs <- future_map(cluster_files, fread)
```

# Count the number of events per reclassified stage

```{r}
# map function to filter each microseismic data to well 3, stage 2
get_stage_event_count <- function(df){
  fread(df) %>%
    group_by(class_well, class_stage) %>%
    summarize(n = n()) %>%
    pull(n) %>%
    max()
}

max_stage_count <- map_dbl(.x = tagged_ms_files, get_stage_event_count)
max_stage_count %>% sd()

```

# Get totals for each run

```{r}
cluster_example <- cluster_dfs[[1]]

get_quantiles <- function(x){
  med_hf = x %>% filter(hf == TRUE) %>% pull(plane_strike) %>% ifelse(. > pi, . - pi, .) %>% median() * 180 / pi
  upp_hf = x %>% filter(hf == TRUE) %>% pull(plane_strike) %>% ifelse(. > pi, . - pi, .) %>% quantile(., 0.25) * 180 / pi
  low_hf = x %>% filter(hf == TRUE) %>% pull(plane_strike) %>% ifelse(. > pi, . - pi, .) %>% quantile(., 0.75) * 180 / pi
  med_is = x %>% filter(hf == FALSE) %>% pull(plane_strike) %>% ifelse(. > pi, . - pi, .) %>% median() * 180 / pi
  upp_is = x %>% filter(hf == FALSE) %>% pull(plane_strike) %>% ifelse(. > pi, . - pi, .) %>% quantile(., 0.25) * 180 / pi
  low_is = x %>% filter(hf == FALSE) %>% pull(plane_strike) %>% ifelse(. > pi, . - pi, .) %>% quantile(., 0.75) * 180 / pi
  data.frame(med_hf, upp_hf, low_hf, med_is, upp_is, low_is)
}

# map number of hf groups using a group_by
map_groups_hf <- function(x) x %>% group_by(well_num_i, stage_num_i, hf) %>% summarize(n = n()) %>% filter(hf == 1) %>% nrow()
map_groups_is <- function(x) x %>% group_by(well_num_i, stage_num_i, hf) %>% summarize(n = n()) %>% filter(hf == 0) %>% nrow()
map_max_clust <- function(x) x %>% group_by(well_num_i, stage_num_i, hf) %>% summarize(n = n()) %>% pull(n) %>% max()

hf_groups = map_dbl(cluster_dfs, map_groups_hf)
mean(hf_groups) %>% round(0)
sd(hf_groups)

is_groups = map_dbl(cluster_dfs, map_groups_is)
mean(is_groups) %>% round(0)
sd(is_groups)

max_clust = map_dbl(cluster_dfs, map_max_clust)
mean(max_clust) %>% round(0)
sd(max_clust)

# get quantiles
map_quantiles_strikes <- map_dfr(cluster_dfs,get_quantiles)
mean(map_quantiles_strikes$med_hf)
sd(map_quantiles_strikes$med_hf)
range(map_quantiles_strikes$low_hf)
range(map_quantiles_strikes$upp_hf)

mean(map_quantiles_strikes$med_is)
sd(map_quantiles_strikes$med_is)
range(map_quantiles_strikes$low_is)
range(map_quantiles_strikes$upp_is)

#define functions to read outputs from a large number of files
n_total <- function(x) x %>% nrow()
n_is <- function(x) x %>% filter(hf == FALSE) %>% nrow()
n_hf <- function(x) x %>% filter(hf == TRUE) %>% nrow()
is_strike_mean <- function(x) x %>% filter(hf == FALSE) %>% pull(plane_strike) %>% mean() * 180 / pi
hf_strike_mean <- function(x) x %>% filter(hf == TRUE) %>% pull(plane_strike) %>% mean() * 180 / pi

mapped_cluster_results <- data.frame(n_total = map_dbl(cluster_dfs, nrow),
                                     n_is = map_dbl(cluster_dfs, n_is),
                                     n_hf = map_dbl(cluster_dfs, n_hf),
                                     mean_strike_is = map_dbl(cluster_dfs, is_strike_mean),
                                     mean_strike_hf = map_dbl(cluster_dfs, hf_strike_mean))

summary_mcr <- mapped_cluster_results %>%
  summarize_all(.funs = c('mean','sd'))

summary_mcr$n_total_mean %>% round(0)
summary_mcr$n_total_sd

get_height_med <- function(x) x %>% dplyr::filter(plane_dip >= (60 * pi / 180)) %>% pull(plane_l2) %>% median()
get_length_med <- function(x) x %>% dplyr::filter(plane_dip >= (60 * pi / 180)) %>% pull(plane_l1) %>% median()

height <- map_dbl(cluster_dfs, get_height_med)
mean(height)
sd(height)

length <- map_dbl(cluster_dfs, get_length_med)
mean(length)
sd(length)
```

# Cluster stability - standard deviation and interquartile range between clusters

```{r}
# get standard deviation and interquartile range of clusters for all the runs
table <- cluster_dfs %>%
  map(function(x) table(x$well_num_i,x$stage_num))

cluster_mean <- matrix(nrow = 8, ncol = 29)
cluster_sd <- matrix(nrow = 8, ncol = 29)
cluster_q25 <- matrix(nrow = 8, ncol = 29)
cluster_q75 <- matrix(nrow = 8, ncol = 29)

for (well in seq(1,8)){
  for (stage in seq(1,29)){
    clust_vector <- map_dbl(table, function(x) x[well,stage])
    cluster_q25[well,stage] <- quantile(clust_vector, 1/4)
    cluster_q75[well,stage] <- quantile(clust_vector, 3/4)
    cluster_mean[well,stage] <- mean(clust_vector)
    cluster_sd[well,stage]  <- sd(clust_vector)
  }
}

cluster_iqr <- cluster_q75 - cluster_q25
```

# Investigate Well 3 Stage 2 Data

```{r}
# map function to filter each microseismic data to well 3, stage 2
get_w3_s2_res <- function(df, n){
  fread(df) %>%
    dplyr::filter(class_well == 3 & class_stage == 2) %>%
    mutate(run_n = n)
}

w3s2_ms_res <- map2_dfr(.x = tagged_ms_files, .y = seq(1:length(tagged_ms_files)), get_w3_s2_res)

w3s2events <- w3s2_ms_res %>%
  group_by(run_n) %>%
  summarize(n = n())

mean(w3s2events$n)
```

```{r}
# What is the range of location uncertainties?
mean(gmm_res_dfs$ux)
IQR(gmm_res_dfs$ux)
mean(gmm_res_dfs$uy)
IQR(gmm_res_dfs$uy)
mean(gmm_res_dfs$uz)
IQR(gmm_res_dfs$uz)

# What is the perforated stage length of well 3, stage 2?
# W3S2 is a good example of a very uncertain perforation length and open hole completion
comp_df <- read_csv("data/updated_completions.csv")
surv_df <- read_csv("data/updated_surveys.csv")

# How many events do we have in W3S2 after reclassification
reclass_W3S2 <- gmm_res_dfs %>%
  group_by(run_n) %>%
  filter(class_well == 3, class_stage == 2) %>%
  summarize(n = n())

original_W3S2 <- gmm_res_dfs %>%
  group_by(run_n) %>%
  filter(operator_well_num == 3, operator_stage_num == 2) %>%
  summarize(n = n())

gmm_res_dfs %>%
  group_by(run_n) %>%
  summarize(n = n())

gmm_res_dfs[1:1000,] %>% View()

hist(original_W3S2$n)

# How many induced seismicity 
# In all 10,000 runs, there are only thr
distinct_is_clusters <- gmm_res_dfs %>%
  group_by(run_n) %>%
  filter(bool == 1) %>%
  summarize(n_distinct(cluster))

(distinct_is_clusters)

  summarize(n(cluster))
  pull(cluster) %>%
  unique()


group_by(cluster) %>%
  summarize(IS = sum(bool))
# How many induced seismicity clusters are there?


gg_cluster_plot(ms_df = gmm_res_dfs %>% filter(run_n == 1),
                comp_df = comp_df,
                surv_df = surv_df)
```

ggplot tile

```{r}
mat_to_df <- function(mat, gather = TRUE){
  out_df <- as.data.frame(mat, row.names = seq(1,nrow(mat)))
  colnames(out_df) <- seq(1,ncol(mat))
  out_df <- cbind(out_df, well = rownames(out_df) %>% as.numeric)
  
  if(gather){
    out_df <- gather(data = out_df, key = stage, value = cluster, -well)
    out_df$stage <- out_df$stage %>% as.numeric
  }
  
  out_df
}

sd <- mat_to_df(cluster_sd) %>%
  mutate(meas = 'Standard Deviation')

iqr <- mat_to_df(cluster_iqr) %>%
  mutate(meas = 'Interquartile Range')

uncertainity_measures = rbind(sd,iqr)

ggplot(uncertainity_measures) +
  geom_tile(aes(x = stage, y = well, fill = cluster)) +
  scale_fill_viridis_c(name = 'Measure') +
  coord_equal() +
  theme_minimal() +
  facet_wrap(meas ~ ., nrow = 2) +
  ggsave('./graphs/ms_only_stats.jpg',width = 8, height =8, dpi = 600)

run_summary_df <- mapped_cluster_results %>% dplyr::select(n_total, n_is, n_hf)
colnames(run_summary_df) <- c('All Clusters','HF Clusters','IS Clusters')

ggplot(gather(run_summary_df)) +
  geom_histogram(aes(x = value), bins = 22) +
  facet_wrap(. ~ key, scales = 'free_x') +
  theme_minimal() +
  ggsave('./ms_only_hist.jpg',width = 8, height =4, dpi = 600)
```
